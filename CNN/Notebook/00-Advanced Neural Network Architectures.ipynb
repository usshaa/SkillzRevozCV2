{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Advanced Neural Network Architectures\n",
    "\n",
    "**Convolutional Neural Networks (CNNs)**\n",
    "\n",
    "#### CNN Architecture and Operations\n",
    "\n",
    "Convolutional Neural Networks (CNNs) are specialized deep learning architectures designed for processing structured grid-like data, such as images.\n",
    "\n",
    "<img src=\"https://th.bing.com/th/id/OIP.tflhgiEHGYsBiCmZF8jp1gHaED?w=768&h=421&rs=1&pid=ImgDetMain\">\n",
    "\n",
    "- **Convolutional Layers**:\n",
    "  - Introduction to convolution operation:\n",
    "    - Applies filters (kernels) over input images to extract features.\n",
    "    - Stride and padding for controlling output dimensions and handling edges.\n",
    "  - Multiple convolutional layers to learn hierarchical features:\n",
    "    - Edge detection in early layers,\n",
    "    - High-level features (e.g., textures, patterns) in deeper layers.\n",
    "\n",
    "- **Pooling Layers**:\n",
    "  - Types of pooling (e.g., max pooling, average pooling):\n",
    "    - Reduces spatial dimensions (width, height) of feature maps.\n",
    "    - Enhances translation invariance and reduces computational complexity.\n",
    "  \n",
    "- **Activation Functions in CNNs**:\n",
    "  - Typically ReLU (Rectified Linear Unit) used to introduce non-linearity.\n",
    "  - Applied after each convolutional and pooling layer to model complex relationships in data.\n",
    "\n",
    "#### Applications in Image Processing\n",
    "\n",
    "CNNs revolutionized image processing tasks, achieving state-of-the-art performance in various applications:\n",
    "\n",
    "- **Object Detection**:\n",
    "  - Localization and classification of objects within images (e.g., YOLO, Faster R-CNN).\n",
    "  - Applications in autonomous driving, surveillance systems.\n",
    "  \n",
    "- **Image Classification**:\n",
    "  - Assigning labels to images based on extracted features.\n",
    "  - Examples include MNIST digit classification, ImageNet classification challenge.\n",
    "  \n",
    "- **Semantic Segmentation**:\n",
    "  - Pixel-level classification to distinguish objects and their boundaries in images.\n",
    "  - Applications in medical imaging, satellite imagery analysis.\n",
    "  \n",
    "- **Image Generation and Style Transfer**:\n",
    "  - Generating new images (e.g., DeepDream) or transferring styles between images (e.g., neural style transfer).\n",
    "  - Creative applications in art and design."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Layer\n",
    "\n",
    "**Concept:**\n",
    "- **Convolution:** A mathematical operation that blends two functions to produce a third one. In the context of CNNs, it involves applying a filter (also known as a kernel) over an input image to extract features.\n",
    "\n",
    "**Example:**\n",
    "- **Input Image:** Consider a grayscale image of size 5x5 pixels (each pixel represented by a value between 0 and 255).\n",
    "\n",
    "  ```\n",
    "  [140, 130, 125, 120, 115]\n",
    "  [135, 132, 128, 124, 119]\n",
    "  [137, 131, 129, 125, 120]\n",
    "  [139, 134, 130, 126, 122]\n",
    "  [141, 136, 132, 128, 123]\n",
    "  ```\n",
    "\n",
    "- **Filter (Kernel):** A small matrix applied to the input image to perform convolution. Let's use a 3x3 filter for simplicity.\n",
    "\n",
    "  ```\n",
    "  [1, 0, -1]\n",
    "  [1, 0, -1]\n",
    "  [1, 0, -1]\n",
    "  ```\n",
    "\n",
    "- **Convolution Operation:** Slide the filter over the input image, computing element-wise multiplications and summing them up to produce a single value for the output feature map.\n",
    "\n",
    "  - Place the filter at the top-left corner of the input image.\n",
    "  - Compute the dot product between the filter and the corresponding patch of the image:\n",
    "    ```\n",
    "    140*1 + 130*0 + 125*(-1)\n",
    "    135*1 + 132*0 + 128*(-1)\n",
    "    137*1 + 131*0 + 129*(-1)\n",
    "    ```\n",
    "    Sum = `30`\n",
    "\n",
    "  - Repeat this process by sliding the filter across the entire image, computing each output value to form a feature map."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualization:** Here's how the convolution operation works visually:\n",
    "\n",
    "- **Convolution with Filter:**\n",
    "\n",
    "  <img src=\"https://miro.medium.com/max/1400/1*ciDgQEjViWLnCbmX-EeSrA.gif\" alt=\"Convolution GIF\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Pooling Layer (Max Pooling)\n",
    "\n",
    "**Concept:**\n",
    "- **Pooling:** A downsampling operation that reduces the spatial dimensions of the feature map while retaining the most important information. Max pooling, for example, retains the maximum value from each patch of the feature map.\n",
    "\n",
    "**Example:**\n",
    "- **Feature Map:** Suppose we have a 4x4 feature map after convolution.\n",
    "\n",
    "  ```\n",
    "  [2, 1, 1, 3]\n",
    "  [1, 2, 0, 4]\n",
    "  [3, 2, 1, 0]\n",
    "  [0, 1, 2, 4]\n",
    "  ```\n",
    "\n",
    "- **Max Pooling Operation:** Apply a 2x2 pooling window with a stride of 2 (common setting).\n",
    "\n",
    "  - Move a 2x2 window across the feature map.\n",
    "  - Take the maximum value from each window as the output for the pooled feature map.\n",
    "\n",
    "**Visualization:** Here's a visual representation of max pooling:\n",
    "\n",
    "<img src=\"https://cdn-images-1.medium.com/max/726/1*fXxDBsJ96FKEtMOa9vNgjA.gif\" alt=\"Convolution GIF\">\n",
    "\n",
    "### 3. Fully Connected Layer\n",
    "\n",
    "**Concept:**\n",
    "- **Fully Connected (FC) Layer:** Neurons in a fully connected layer have connections to all activations in the previous layer, similar to traditional neural networks.\n",
    "\n",
    "**Example:**\n",
    "- **Flattened Features:** Flatten the pooled feature map into a 1D vector.\n",
    "\n",
    "  ```\n",
    "  [2, 1, 1, 3, 1, 2, 0, 4, 3, 2, 1, 0, 0, 1, 2, 4]\n",
    "  ```\n",
    "\n",
    "- **Weights and Biases:** Each neuron in the FC layer is connected to every element in this flattened vector.\n",
    "\n",
    "- **Activation Function:** Apply an activation function (e.g., ReLU) to introduce non-linearity.\n",
    "\n",
    "### 4. Output Layer\n",
    "\n",
    "**Concept:**\n",
    "- **Output Layer:** Produces the final output of the network, usually representing class scores in classification tasks.\n",
    "\n",
    "**Example:**\n",
    "- **Classification:** If we're classifying digits (0-9), the output layer might have 10 neurons (one for each class).\n",
    "\n",
    "- **Softmax Activation:** Often used to convert raw scores into probabilities.\n",
    "\n",
    "### Summary\n",
    "\n",
    "CNNs leverage convolutional layers to extract features, pooling layers to reduce dimensionality, fully connected layers for classification/regression, and activation functions to introduce non-linearity. Each layer type plays a crucial role in learning hierarchical representations from input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
